#!/bin/bash
set -e
set -x

# =========================================================
# Setup and Testing Script for Refactored Authentication Workflow
# =========================================================
# 
# This script helps apply the refactored configuration and test it.
#
# If you're experiencing hanging issues or timeout problems, you can 
# run this script with different options:
#
# For fast setup with minimal health checks (fastest):
#   FAST_SETUP=true ./scripts/setup-and-test.sh
#
# To skip just URL health checks (medium):
#   SKIP_URL_CHECKS=true ./scripts/setup-and-test.sh
#
# To skip just protocol detection (slower):
#   SKIP_PROTOCOL_DETECTION=true ./scripts/setup-and-test.sh
#
# To skip Keycloak health checks (useful if Keycloak checks hang):
#   SKIP_KEYCLOAK_CHECKS=true ./scripts/setup-and-test.sh
#
# You can combine these settings as needed.
# =========================================================

# Turn off command echoing (we don't want to see every command in the output)
set +x

# Color codes for prettier output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
RESET='\033[0m'
BOLD='\033[1m'
DIM='\033[2m'

# Emoji aliases for visual cues
EMOJI_CHECK="‚úÖ "
EMOJI_WARNING="‚ö†Ô∏è  "
EMOJI_ERROR="‚ùå "
EMOJI_INFO="‚ÑπÔ∏è  "
EMOJI_ROCKET="üöÄ "
EMOJI_GEAR="‚öôÔ∏è  "
EMOJI_HOURGLASS="‚è≥ "
EMOJI_CLOCK="üïí "
EMOJI_SPARKLES="‚ú® "

# Function to print a success message
success() {
  echo -e "${GREEN}${EMOJI_CHECK}${1}${RESET}"
}

# Function to print a warning message
warning() {
  echo -e "${YELLOW}${EMOJI_WARNING}WARNING: ${1}${RESET}"
}

# Function to print an error message
error() {
  echo -e "${RED}${EMOJI_ERROR}ERROR: ${1}${RESET}"
}

# Function to print an info message
info() {
  echo -e "${BLUE}${EMOJI_INFO}${1}${RESET}"
}

# Function to print section headers
print_header() {
  echo
  echo -e "${WHITE}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
  echo -e "${WHITE}${BOLD}   ${1}${RESET}"
  echo -e "${WHITE}${BOLD}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${RESET}"
  CURRENT_PHASE="$1"
}

# Function to print sub-headers / steps
print_step() {
  echo
  echo -e "${CYAN}${BOLD}‚ñ∂ ${1}${RESET}"
  echo -e "${CYAN}${DIM}$(printf '%.s‚îÄ' $(seq 1 50))${RESET}"
  CURRENT_PHASE="$1"
}

# Enable trace mode for debugging if debug is enabled
if [ "$DEBUG" = "true" ]; then
  set -x  # Enable command echoing for debugging
fi

# Function to show progress
show_progress() {
  echo -e "${MAGENTA}${EMOJI_GEAR}${1}${RESET}"
}

# Function to show debug info
debug() {
  if [ "$DEBUG" = "true" ]; then
    echo -e "${DIM}DEBUG: ${1}${RESET}"
  fi
}

# Function to print elapsed time
print_elapsed_time() {
  local DURATION=$1
  local HOURS=$((DURATION / 3600))
  local MINUTES=$(((DURATION % 3600) / 60))
  local SECONDS=$((DURATION % 60))
  
  if [ $HOURS -gt 0 ]; then
    echo -e "${DIM}${EMOJI_CLOCK}Elapsed time: ${HOURS}h ${MINUTES}m ${SECONDS}s${RESET}"
  elif [ $MINUTES -gt 0 ]; then
    echo -e "${DIM}${EMOJI_CLOCK}Elapsed time: ${MINUTES}m ${SECONDS}s${RESET}"
  else
    echo -e "${DIM}${EMOJI_CLOCK}Elapsed time: ${SECONDS}s${RESET}"
  fi
}

# Function for platform-independent sed usage
portable_sed() {
  local pattern=$1
  local file=$2
  
  # Check which platform we're on and use the appropriate sed command
  if [ "$(uname)" == "Darwin" ]; then
    # macOS version needs an empty string for -i
    sed -i '' "$pattern" "$file"
  else
    # Linux version doesn't need the empty string
    sed -i "$pattern" "$file"
  fi
}

# Function for improved error handling
handle_error() {
  local exit_code=$1
  local operation=$2
  
  if [ $exit_code -ne 0 ]; then
    error "$operation failed with exit code $exit_code"
    
    # If FAIL_FAST is enabled, exit immediately
    if [ "$FAIL_FAST" = "true" ]; then
      exit $exit_code
    fi
    
    return 1
  fi
  
  return 0
}

# Function for standardized timeout handling
wait_with_timeout() {
  local operation=$1
  local timeout=$2
  local check_cmd=$3
  
  local start_time=$(date +%s)
  local iteration=0
  
  show_progress "Waiting for: $operation (timeout: ${timeout}s)"
  
  while true; do
    # Run the check command
    if eval "$check_cmd"; then
      success "$operation is now available"
      return 0
    fi
    
    # Check for timeout
    local current_time=$(date +%s)
    local elapsed=$((current_time - start_time))
    
    if [ $elapsed -ge $timeout ]; then
      warning "Timeout after ${elapsed}s waiting for: $operation"
      return 1
    fi
    
    # Show progress every 5 iterations
    iteration=$((iteration + 1))
    if [ $((iteration % 5)) -eq 0 ]; then
      echo -e "${YELLOW}${EMOJI_HOURGLASS} Still waiting for $operation... (${elapsed}s elapsed)${RESET}"
    fi
    
    # Adaptive sleep: shorter at the beginning, longer after waiting a while
    if [ $elapsed -lt 30 ]; then
      sleep 2  # Fast polling initially
    else
      sleep 5  # Slower polling after 30 seconds
    fi
  done
}

# Function to check Docker Compose service health
check_compose_health() {
  local expected_running=$1
  local services_to_check=$2
  local timeout=${3:-60}  # Default 60 seconds timeout
  
  print_step "Checking Docker Compose Services Health"
  show_progress "Expecting $expected_running running services"
  
  # Initialize timer
  local start_time=$(date +%s)
  
  while true; do
    # Get current running services count
    local actual_running=0
    
    if [ -n "$services_to_check" ]; then
      # Check specific services if provided
      for service in $services_to_check; do
        if docker-compose ps --services --filter "status=running" | grep -q "^$service$"; then
          actual_running=$((actual_running + 1))
        fi
      done
    else
      # Check all services
      actual_running=$(docker-compose ps --services --filter "status=running" | wc -l | tr -d ' ')
    fi
    
    # If we have the expected number, we're good
    if [ $actual_running -ge $expected_running ]; then
      success "All expected services are running ($actual_running/$expected_running)"
      return 0
    fi
    
    # Check if we exceeded the timeout
    local current_time=$(date +%s)
    local elapsed=$((current_time - start_time))
    
    if [ $elapsed -ge $timeout ]; then
      warning "Timeout waiting for services to start. Only $actual_running/$expected_running running after ${elapsed}s"
      show_container_summary
      return 1
    fi
    
    # Show progress
    echo -e "${YELLOW}${EMOJI_HOURGLASS} Waiting for services to start: $actual_running/$expected_running (${elapsed}s elapsed)${RESET}"
    sleep 5
  done
}

# Track execution time with a human-readable display
start_timer() {
  START_TIME=$(date +%s)
}

# Start the timer for the whole process
start_timer

# Display welcome message
clear
echo -e "${BLUE}${BOLD}"
echo "============================================================"
echo "  ${EMOJI_ROCKET}DIVE25 - Authentication Workflow Setup Script${EMOJI_ROCKET}  "
echo "============================================================"
echo -e "${RESET}"
echo -e "This script will set up and configure the DIVE25 authentication system."
echo

# Check if curl_tools container is running
print_step "Checking if curl_tools container is running"
export CURL_TOOLS_CONTAINER=${CURL_TOOLS_CONTAINER:-"${PROJECT_PREFIX:-dive25}-curl-tools"}
if ! docker ps | grep -q "$CURL_TOOLS_CONTAINER"; then
  show_progress "curl_tools container not running. Starting it now..."
  docker-compose up -d curl_tools
  
  # Wait for it to be ready
  show_progress "Waiting for curl_tools container to be ready..."
  sleep 5
  
  if docker ps | grep -q "$CURL_TOOLS_CONTAINER"; then
    success "curl_tools container is now running and ready for use"
  else
    error "Failed to start curl_tools container. Please check Docker logs."
    exit 1
  fi
else
  success "curl_tools container is already running"
fi

# Ensure environment variables are properly exported
export SKIP_KEYCLOAK_CHECKS=${SKIP_KEYCLOAK_CHECKS:-true}
export FAST_SETUP=${FAST_SETUP:-true}
export SKIP_URL_CHECKS=${SKIP_URL_CHECKS:-false}
export SKIP_PROTOCOL_DETECTION=${SKIP_PROTOCOL_DETECTION:-false}
export DEBUG=${DEBUG:-false}

# Load Keycloak environment variables
if [ -f "keycloak.env" ]; then
  info "Loading Keycloak environment variables from keycloak.env file..."
  # Create a sanitized version of the env file
  sanitized_file="keycloak.env.sanitized"
  cp "keycloak.env" "$sanitized_file"
  
  # Source the sanitized environment file
  source "$sanitized_file"
  export POSTGRES_CONTAINER_NAME
  export POSTGRES_HOST
  export POSTGRES_PORT
  export POSTGRES_DB
  export POSTGRES_USER
  export POSTGRES_PASSWORD
  export KEYCLOAK_CONTAINER_NAME
  export KEYCLOAK_SERVICE_NAME
  export KEYCLOAK_CONFIG_CONTAINER_NAME
  export KEYCLOAK_ADMIN
  export KEYCLOAK_ADMIN_PASSWORD
  export KEYCLOAK_HTTP_PORT
  export KEYCLOAK_HTTPS_PORT
  export KEYCLOAK_PORT
  export KEYCLOAK_REALM
  export KEYCLOAK_CLIENT_ID_FRONTEND
  export KEYCLOAK_CLIENT_ID_API
  export KEYCLOAK_CLIENT_SECRET
  export BASE_DOMAIN
  export KEYCLOAK_SUBDOMAIN
  export FRONTEND_SUBDOMAIN
  export API_SUBDOMAIN
  export KONG_SUBDOMAIN
  export FRONTEND_PORT
  export API_PORT
  export CURL_TOOLS_CONTAINER
  export CORS_ALLOWED_ORIGINS
  
  # Clean up
  rm -f "$sanitized_file"
  
  success "Keycloak environment variables loaded successfully"
else
  warning "Keycloak environment file (keycloak.env) not found. Using default configuration."
fi

# Always skip Keycloak health checks to avoid hanging issues
info "Automatically setting SKIP_KEYCLOAK_CHECKS=true to avoid hanging on Keycloak health checks"
export SKIP_KEYCLOAK_CHECKS=true

# Load environment variables from .env file
if [ -f ".env" ]; then
  info "Loading environment variables from .env file..."
  
  # Function to sanitize environment files to handle special characters properly
  sanitize_env_file() {
    local env_file="$1"
    local sanitized_file="${env_file}.sanitized"
    
    # Create a sanitized copy of the environment file
    cp "$env_file" "$sanitized_file"
    
    # Comment out problematic security headers to avoid execution issues
    portable_sed 's/^\(KEYCLOAK_SECURITY_HEADERS=.*\)/#\1/' "$sanitized_file"
    portable_sed 's/^\(GLOBAL_SECURITY_HEADERS=.*\)/#\1/' "$sanitized_file"
    
    # No need to remove backup files - portable_sed handles this for each platform
    
    echo "$sanitized_file"
  }
  
  # Create sanitized version of the env file
  SANITIZED_ENV=$(sanitize_env_file ".env")
  
  # Source the sanitized environment file
  source "$SANITIZED_ENV"
  
  # Clean up
  rm -f "$SANITIZED_ENV"
  
  success "Environment variables loaded successfully"
else
  warning "Environment file (.env) not found. Using default configuration."
fi

# Early creation of realm-ready marker file to unblock dependencies
print_step "Preparing Keycloak configuration"
show_progress "Creating realm-ready marker file to unblock dependent services..."
KEYCLOAK_CONFIG_DATA_VOLUME=$(docker volume ls --format "{{.Name}}" | grep keycloak_config_data || true)
debug "KEYCLOAK_CONFIG_DATA_VOLUME='$KEYCLOAK_CONFIG_DATA_VOLUME'"

if [ -n "$KEYCLOAK_CONFIG_DATA_VOLUME" ]; then
    debug "Volume found, attempting to create marker file"
    docker run --rm -v "$KEYCLOAK_CONFIG_DATA_VOLUME:/data" alpine:latest sh -c "mkdir -p /data && touch /data/realm-ready && echo 'direct-creation' > /data/realm-ready" > /dev/null 2>&1
    success "Realm-ready marker file created successfully"
else
    warning "Could not find keycloak_config_data volume, continuing anyway"
fi

# Set default values for variables if not defined in .env
KEYCLOAK_CONTAINER_NAME=${KEYCLOAK_CONTAINER_NAME:-keycloak}
KEYCLOAK_HTTP_PORT=${KEYCLOAK_HTTP_PORT:-8080}
KEYCLOAK_CONFIG_CONTAINER_NAME=${KEYCLOAK_CONFIG_CONTAINER_NAME:-keycloak-config}

# Set up trap handlers
trap 'error "Script interrupted. Cleaning up..."; exit 1' INT
trap 'echo; echo; warning "ATTENTION: Script may be hanging. If stuck, press Ctrl+C to abort. (Currently in: $CURRENT_PHASE)"; echo' ALRM

# Enable timeout alerting
if command -v perl >/dev/null 2>&1; then
  (perl -e 'alarm shift @ARGV; exec @ARGV' 1800 kill -ALRM $$) & # 30-minute global timeout
  TIMEOUT_PID=$!
  trap "kill $TIMEOUT_PID 2>/dev/null" EXIT
elif command -v timeout >/dev/null 2>&1; then
  # If perl isn't available but GNU timeout is
  ( sleep 1800 && kill -ALRM $$ )& # 30-minute global timeout
  TIMEOUT_PID=$!
  trap "kill $TIMEOUT_PID 2>/dev/null" EXIT
else
  # Fallback for macOS without timeout command
  info "Timeout command not available. Long-running operations will not time out automatically."
fi

# Configuration options - set these for faster setup
SKIP_URL_CHECKS=${SKIP_URL_CHECKS:-false}  # Set to true to skip all URL health checks
SKIP_PROTOCOL_DETECTION=${SKIP_PROTOCOL_DETECTION:-false}  # Set to true to skip protocol detection
FAST_SETUP=${FAST_SETUP:-false}  # Set to true for faster setup with minimal checks
SKIP_API_CHECK=${SKIP_API_CHECK:-false}  # Set to true to skip API health checks specifically
KONG_CONFIGURED=false  # Flag to track Kong configuration status
USE_IMPROVED_FUNCTIONS=true  # Set to true to use the improved functions with portable_sed

# If FAST_SETUP is true, skip all advanced checks
if [ "$FAST_SETUP" = "true" ]; then
  SKIP_URL_CHECKS=true
  SKIP_PROTOCOL_DETECTION=true
  SKIP_API_CHECK=true
  SKIP_KEYCLOAK_CHECKS=true
  info "Fast setup mode enabled - skipping most health and URL checks for quicker deployment"
fi

# === ADD NEW SECTION FOR FIXING IDENTITY PROVIDERS AFTER KEYCLOAK CONFIGURATION ===

# Function to fix identity provider configurations to use Keycloak itself
fix_identity_providers() {
  print_step "Fixing Identity Provider Configurations"
  show_progress "Updating IdP configurations to use Keycloak as a mock provider..."
  
  # Add a timeout for the operation
  local TIMEOUT=120  # 2 minutes timeout
  local start_time=$(date +%s)
  
  # Load dynamic domain and port values from environment
  local base_domain=${BASE_DOMAIN:-dive25.local}
  local keycloak_subdomain=${KEYCLOAK_SUBDOMAIN:-keycloak}
  local keycloak_port=${KEYCLOAK_PORT:-8443}
  local keycloak_realm=${KEYCLOAK_REALM:-dive25}
  
  # Ensure all IdP configurations use Keycloak's own endpoints
  for idp_file in keycloak/identity-providers/*-oidc-idp-config.json; do
    # Check for timeout
    local current_time=$(date +%s)
    if [ $((current_time - start_time)) -gt $TIMEOUT ]; then
      warning "Identity provider configuration timeout after ${TIMEOUT}s. Continuing with partial configuration."
      break
    fi
    
    idp_name=$(basename "$idp_file" | sed 's/-idp-config.json//')
    info "Updating $idp_name configuration..."
    
    # Build the base Keycloak URL with environment variables
    local keycloak_base_url="https://${keycloak_subdomain}.${base_domain}:${keycloak_port}/realms/${keycloak_realm}/protocol/openid-connect"
    
    # Fix URLs in the IdP config to point to Keycloak
    show_progress "Updating IdP config: $idp_file"
    sed -i '' -E "s|\"tokenUrl\": \"https://[^/]+/oauth2/token\"|\"tokenUrl\": \"${keycloak_base_url}/token\"|g" "$idp_file"
    sed -i '' -E "s|\"authorizationUrl\": \"https://[^/]+/oauth2/authorize\"|\"authorizationUrl\": \"${keycloak_base_url}/auth\"|g" "$idp_file"
    sed -i '' -E "s|\"jwksUrl\": \"https://[^/]+/oauth2/jwks\"|\"jwksUrl\": \"${keycloak_base_url}/certs\"|g" "$idp_file"
    sed -i '' -E "s|\"userInfoUrl\": \"https://[^/]+/oauth2/userinfo\"|\"userInfoUrl\": \"${keycloak_base_url}/userinfo\"|g" "$idp_file"
    sed -i '' -E "s|\"logoutUrl\": \"https://[^/]+/oauth2/logout\"|\"logoutUrl\": \"${keycloak_base_url}/logout\"|g" "$idp_file"
    
    # Clean up backup files
    rm -f "${idp_file}.bak"
  done
  
  # Run the fix-idps.sh script to apply the changes to the running containers
  if [ -f "keycloak/fix-idps.sh" ]; then
    show_progress "Applying IdP fixes to running Keycloak containers..."
    bash keycloak/fix-idps.sh
    success "Identity provider configurations fixed and applied successfully!"
  else
    warning "keycloak/fix-idps.sh not found, skipping IdP fixes. Changes will apply on next deployment."
  fi
}

# Improved version of fix_identity_providers that uses portable_sed
fix_identity_providers_improved() {
  print_step "Fixing Identity Provider Configurations"
  show_progress "Updating IdP configurations to use Keycloak as a mock provider..."
  
  # Add a timeout for the operation
  local TIMEOUT=120  # 2 minutes timeout
  local start_time=$(date +%s)
  
  # Load dynamic domain and port values from environment
  local base_domain=${BASE_DOMAIN:-dive25.local}
  local keycloak_subdomain=${KEYCLOAK_SUBDOMAIN:-keycloak}
  local keycloak_port=${KEYCLOAK_PORT:-8443}
  local keycloak_realm=${KEYCLOAK_REALM:-dive25}
  
  # Ensure all IdP configurations use Keycloak's own endpoints
  for idp_file in keycloak/identity-providers/*-oidc-idp-config.json; do
    # Check for timeout
    local current_time=$(date +%s)
    if [ $((current_time - start_time)) -gt $TIMEOUT ]; then
      warning "Identity provider configuration timeout after ${TIMEOUT}s. Continuing with partial configuration."
      break
    fi
    
    idp_name=$(basename "$idp_file" | sed 's/-idp-config.json//')
    info "Updating $idp_name configuration..."
    
    # Build the base Keycloak URL with environment variables
    local keycloak_base_url="https://${keycloak_subdomain}.${base_domain}:${keycloak_port}/realms/${keycloak_realm}/protocol/openid-connect"
    
    # Fix URLs in the IdP config to point to Keycloak using portable_sed
    show_progress "Updating IdP config: $idp_file"
    portable_sed "-E s|\"tokenUrl\": \"https://[^/]+/oauth2/token\"|\"tokenUrl\": \"${keycloak_base_url}/token\"|g" "$idp_file"
    portable_sed "-E s|\"authorizationUrl\": \"https://[^/]+/oauth2/authorize\"|\"authorizationUrl\": \"${keycloak_base_url}/auth\"|g" "$idp_file"
    portable_sed "-E s|\"jwksUrl\": \"https://[^/]+/oauth2/jwks\"|\"jwksUrl\": \"${keycloak_base_url}/certs\"|g" "$idp_file"
    portable_sed "-E s|\"userInfoUrl\": \"https://[^/]+/oauth2/userinfo\"|\"userInfoUrl\": \"${keycloak_base_url}/userinfo\"|g" "$idp_file"
    portable_sed "-E s|\"logoutUrl\": \"https://[^/]+/oauth2/logout\"|\"logoutUrl\": \"${keycloak_base_url}/logout\"|g" "$idp_file"
    
    # No need to clean up backup files - portable_sed handles this correctly for each platform
  done
  
  # Run the fix-idps.sh script to apply the changes to the running containers
  if [ -f "keycloak/fix-idps.sh" ]; then
    show_progress "Applying IdP fixes to running Keycloak containers..."
    bash keycloak/fix-idps.sh
    success "Identity provider configurations fixed and applied successfully!"
  else
    warning "keycloak/fix-idps.sh not found, skipping IdP fixes. Changes will apply on next deployment."
  fi
}

# Hook to call the fix_identity_providers function after Keycloak is configured
keycloak_post_config_hook() {
  if [ -z "$KEYCLOAK_CONTAINER" ]; then
    warning "No Keycloak container available for identity provider configuration"
    return 1
  fi
  
  show_progress "Configuring country-specific identity providers..."

  # First check if identity providers are already configured
  if docker exec $KEYCLOAK_CONTAINER test -f /tmp/keycloak-config/idps-configured 2>/dev/null; then
    success "Identity providers are already configured (marker file exists)"
    return 0
  fi
  
  # Check if identity providers already exist by querying Keycloak
  local IDPS=$(docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh config credentials --server http://localhost:8080 --realm master --user admin --password admin 2>/dev/null && \
               docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh get identity-provider/instances -r dive25 2>/dev/null)
  
  # If we have all the expected identity providers, create the marker file and skip
  if echo "$IDPS" | grep -q "usa-oidc" && \
     echo "$IDPS" | grep -q "uk-oidc" && \
     echo "$IDPS" | grep -q "canada-oidc" && \
     echo "$IDPS" | grep -q "australia-oidc" && \
     echo "$IDPS" | grep -q "newzealand-oidc"; then
    success "All identity providers already exist in Keycloak"
    docker exec $KEYCLOAK_CONTAINER bash -c "mkdir -p /tmp/keycloak-config && touch /tmp/keycloak-config/idps-configured"
    return 0
  fi
  
  # Copy our IdP configurations to Keycloak container
  show_progress "Copying identity provider configurations to Keycloak..."
  docker exec $KEYCLOAK_CONTAINER mkdir -p /opt/keycloak/data/identity-providers
  
  # Copy each identity provider configuration
  for provider in usa uk canada australia newzealand; do
    local config_file="${PROJECT_ROOT}/keycloak/identity-providers/${provider}-oidc-idp-config.json"
    if [ -f "$config_file" ]; then
      docker cp "$config_file" $KEYCLOAK_CONTAINER:/opt/keycloak/data/identity-providers/
    else
      warning "Identity provider configuration not found: $config_file"
    fi
  done
  
  # Use the Admin CLI to create identity providers
  show_progress "Creating identity providers using Keycloak Admin CLI..."
  
  # Initialize Keycloak admin CLI
  docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh config credentials \
    --server http://localhost:8080 \
    --realm master \
    --user admin \
    --password admin
  
  # Create each identity provider
  for provider in usa uk canada australia newzealand; do
    show_progress "Configuring $provider identity provider..."
    
    # Get the country name (for mappers)
    local country_name
    case "$provider" in
      usa) country_name="USA" ;;
      uk) country_name="UK" ;;
      canada) country_name="Canada" ;;
      australia) country_name="Australia" ;;
      newzealand) country_name="New Zealand" ;;
      *) country_name="$provider" ;;
    esac
    
    # Create or update the identity provider
    if docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh get identity-provider/instances/${provider}-oidc -r dive25 >/dev/null 2>&1; then
      # Provider exists, update it
      docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh update \
        identity-provider/instances/${provider}-oidc -r dive25 \
        -f /opt/keycloak/data/identity-providers/${provider}-oidc-idp-config.json
    else
      # Provider doesn't exist, create it
      docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh create \
        identity-provider/instances -r dive25 \
        -f /opt/keycloak/data/identity-providers/${provider}-oidc-idp-config.json
    fi
    
    # Create country mapper
    docker exec $KEYCLOAK_CONTAINER bash -c "cat > /tmp/country-mapper.json << EOF
{
  \"name\": \"country-of-affiliation\",
  \"identityProviderAlias\": \"${provider}-oidc\",
  \"identityProviderMapper\": \"hardcoded-attribute-idp-mapper\",
  \"config\": {
    \"attribute.name\": \"countryOfAffiliation\",
    \"attribute.value\": \"$country_name\",
    \"user.session.note\": \"false\"
  }
}
EOF"
    
    # Apply the mapper (ignoring errors if already exists)
    docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh create \
      identity-provider/instances/${provider}-oidc/mappers -r dive25 \
      -f /tmp/country-mapper.json >/dev/null 2>&1 || true
  done
  
  # Create marker file to indicate successful configuration
  docker exec $KEYCLOAK_CONTAINER bash -c "mkdir -p /tmp/keycloak-config && touch /tmp/keycloak-config/idps-configured"
  
  success "All identity providers have been configured successfully!"
  return 0
}

# Track current phase for better error reporting
CURRENT_PHASE="Initialization"

# Set a master timeout for the entire process
MASTER_TIMEOUT=600 # 10 minutes
MASTER_START_TIME=$(date +%s)

# Get the directory where this script is located
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
# Get the project root directory (parent directory of the script)
PROJECT_ROOT="$( cd "$SCRIPT_DIR/.." && pwd )"

# Change to the project root directory
cd "$PROJECT_ROOT"

# Function to show container status summary without repeated output
show_container_summary() {
  echo
  echo -e "${BOLD}Container Status Summary:${RESET}"
  
  # Get list of containers and their status
  local containers=$(docker-compose ps --services 2>/dev/null)
  
  if [ -z "$containers" ]; then
    echo -e "  ${YELLOW}${EMOJI_WARNING} No containers found${RESET}"
    return
  fi
  
  # List of known task containers that are expected to exit
  local expected_task_containers=("keycloak-config" "kong-config" "kong-migrations" "curl_tools")
  
  # Count containers by status
  local total=$(echo "$containers" | wc -l | tr -d ' ')
  local running=$(docker-compose ps --services --filter "status=running" 2>/dev/null | wc -l | tr -d ' ')
  local exited=$(docker-compose ps --services --filter "status=exited" 2>/dev/null | wc -l | tr -d ' ')
  local other=$((total - running - exited))
  
  # Count expected task containers that have exited
  local expected_exits=0
  local unexpected_exits=0
  
  for container in $(docker-compose ps --services --filter "status=exited" 2>/dev/null); do
    # Check if this is a known task container
    local is_task_container=false
    for task in "${expected_task_containers[@]}"; do
      if [[ "$container" == *"$task"* ]]; then
        is_task_container=true
        expected_exits=$((expected_exits + 1))
        break
      fi
    done
    
    # If not a task container, check exit code
    if [ "$is_task_container" = false ]; then
      local status_line=$(docker-compose ps $container 2>/dev/null | grep "Exit" || echo "")
      local exit_code=""
      
      if [ -n "$status_line" ]; then
        # Extract the exit code using sed, which is more portable
        exit_code=$(echo "$status_line" | sed -n 's/.*Exit (\([0-9]\+\)).*/\1/p')
      fi
      
      if [ "$exit_code" = "0" ]; then
        expected_exits=$((expected_exits + 1))
      else
        unexpected_exits=$((unexpected_exits + 1))
      fi
    fi
  done
  
  # Adjust total count to exclude task containers for clearer reporting
  local adjusted_total=$((total - expected_exits))
  
  # Print summary
  echo -e "  ${GREEN}‚ñ£ Running:${RESET} $running/${adjusted_total} ${DIM}(excluding expected task containers)${RESET}"
  
  if [ $expected_exits -gt 0 ]; then
    echo -e "  ${BLUE}‚ñ£ Task containers completed:${RESET} $expected_exits ${DIM}(expected to exit)${RESET}"
  fi
  
  if [ $unexpected_exits -gt 0 ]; then
    echo -e "  ${RED}‚ñ£ Exited unexpectedly:${RESET} $unexpected_exits/${adjusted_total}"
  fi
  
  if [ $other -gt 0 ]; then
    echo -e "  ${YELLOW}‚ñ£ Other status:${RESET} $other/${adjusted_total}"
  fi
  
  # Show non-running containers details if needed
  if [ $unexpected_exits -gt 0 ] || [ $other -gt 0 ]; then
    echo
    echo -e "${BOLD}Details for problematic containers:${RESET}"
    
    # Show containers that exited unexpectedly (not task containers and non-zero exit)
    for container in $(docker-compose ps --services --filter "status=exited" 2>/dev/null); do
      # Skip known task containers
      local is_task_container=false
      for task in "${expected_task_containers[@]}"; do
        if [[ "$container" == *"$task"* ]]; then
          is_task_container=true
          break
        fi
      done
      
      if [ "$is_task_container" = true ]; then
        continue  # Skip expected task containers
      fi
      
      # Check exit code
      local status_line=$(docker-compose ps $container 2>/dev/null | grep "Exit" || echo "")
      local exit_code=""
      
      if [ -n "$status_line" ]; then
        exit_code=$(echo "$status_line" | sed -n 's/.*Exit (\([0-9]\+\)).*/\1/p')
      fi
      
      if [ "$exit_code" != "0" ]; then
        echo -e "  ${RED}${container}:${RESET} Exit ($exit_code)"
      fi
    done
    
    # Show containers in other states
    for container in $(docker-compose ps --services 2>/dev/null); do
      # Skip running containers
      if docker-compose ps --services --filter "status=running" 2>/dev/null | grep -q "^$container$"; then
        continue
      fi
      # Skip exited containers (already handled)
      if docker-compose ps --services --filter "status=exited" 2>/dev/null | grep -q "^$container$"; then
        continue
      fi
      # Show other containers
      local status=$(docker-compose ps $container 2>/dev/null | tail -n 1 | awk '{print $3, $4, $5}')
      echo -e "  ${YELLOW}${container}:${RESET} $status"
    done
  else
    echo
    if [ $running -eq $adjusted_total ]; then
      echo -e "${GREEN}${EMOJI_CHECK} All application containers are running as expected.${RESET}"
      
      if [ $expected_exits -gt 0 ]; then
        echo -e "${BLUE}${EMOJI_INFO}Task containers have completed their jobs and exited normally.${RESET}"
      fi
    else
      echo -e "${GREEN}${EMOJI_CHECK} No problematic containers detected.${RESET}"
    fi
  fi
}

# Function to check if a command exists
command_exists() {
  command -v "$1" >/dev/null 2>&1
}

# Function to get container name based on service
get_container_name() {
  local service_name=$1
  local default_prefix="dive25"
  
  # Try docker-compose first (most reliable approach)
  local container_id=$(docker-compose ps -q $service_name 2>/dev/null)
  if [ -n "$container_id" ]; then
    local name=$(docker inspect --format '{{.Name}}' $container_id 2>/dev/null | sed 's/^\///')
    if [ -n "$name" ]; then
      echo "$name"
      return 0
    fi
  fi
  
  # Use a consistent project prefix - determine it once using docker-compose
  if [ -z "$PROJECT_PREFIX" ]; then
    # First try to get from docker-compose.yml
    if [ -f "docker-compose.yml" ]; then
      export PROJECT_PREFIX=$(grep -o "^[a-zA-Z0-9_-]*" docker-compose.yml | head -1 || echo "$default_prefix")
    fi
    
    # If still empty, use default
    if [ -z "$PROJECT_PREFIX" ]; then
      export PROJECT_PREFIX="$default_prefix"
    fi
    
    debug "Setting project prefix to: $PROJECT_PREFIX"
  fi
  
  # Try direct match first (most reliable)
  if docker ps -a --format '{{.Names}}' | grep -q "^${PROJECT_PREFIX}-${service_name}$"; then
    echo "${PROJECT_PREFIX}-${service_name}"
    return 0
  fi
  
  # Try with underscores instead of hyphens
  if docker ps -a --format '{{.Names}}' | grep -q "^${PROJECT_PREFIX}_${service_name}$"; then
    echo "${PROJECT_PREFIX}_${service_name}"
    return 0
  fi
  
  # Try with just the service name
  if docker ps -a --format '{{.Names}}' | grep -q "^${service_name}$"; then
    echo "${service_name}"
    return 0
  fi
  
  # Try pattern matching as last resort
  local pattern_match=$(docker ps -a --format '{{.Names}}' | grep -E "(^|[-_])${service_name}($|[-_])" | head -n1)
  if [ -n "$pattern_match" ]; then
    echo "$pattern_match"
    return 0
  fi
  
  # Default to standard naming convention
  echo "${PROJECT_PREFIX}-${service_name}"
}

# Function to wait for service availability with improved reliability
wait_for_service() {
  local service_name=$1
  local url=$2
  local timeout=$3
  local counter=0
  
  show_progress "Waiting for $service_name to be ready..."
  
  # First check if the Docker container is running
  local service_name_lower=$(echo "$service_name" | tr '[:upper:]' '[:lower:]' | tr -d '[:space:]')
  local container_name=$(get_container_name "$service_name_lower")
  
  # Check if container exists
  if ! docker ps -a | grep -q "$container_name"; then
    info "Container $container_name does not exist, trying alternate naming formats..."
    # Try alternate container name formats
    local alt_formats=("dive25-$service_name_lower" "dive25_$service_name_lower" "$service_name_lower")
    local found=false
    
    for format in "${alt_formats[@]}"; do
      if docker ps -a | grep -q "$format"; then
        container_name="$format"
        info "Found container with name: $container_name"
        found=true
        break
      fi
    done
    
    if ! $found; then
      warning "Could not find container for $service_name. Container health check will be skipped."
      # Continue with URL check if provided
    fi
  fi
  
  # Check if container is running (if found)
  if docker ps -a | grep -q "$container_name"; then
    if ! docker ps | grep -q "$container_name"; then
      warning "Container $container_name exists but is not running."
      echo "Container status: $(docker inspect --format '{{.State.Status}}' "$container_name")"
      return 1
    else
      success "$service_name container is running"
    fi
  fi
  
  # Skip URL checks if requested or URL is empty
  if [ "$SKIP_URL_CHECKS" = "true" ] || [ -z "$url" ]; then
    info "Skipping URL availability check for $service_name."
    return 0
  fi
  
  # Determine if we should use curl or wget
  local http_tool=""
  if command -v curl >/dev/null 2>&1; then
    http_tool="curl"
  elif command -v wget >/dev/null 2>&1; then
    http_tool="wget"
  else
    warning "Neither curl nor wget found. Skipping URL availability check."
    return 0
  fi
  
  # Function to check URL availability
  check_url() {
    local url=$1
    local tool=$2
    
    if [ "$tool" = "curl" ]; then
      # Using curl with safe options
      if curl -sSL --max-time 5 --retry 0 --head "$url" >/dev/null 2>&1; then
        return 0
      else
        return 1
      fi
    elif [ "$tool" = "wget" ]; then
      # Using wget with safe options
      if wget --timeout=5 --tries=1 --spider "$url" >/dev/null 2>&1; then
        return 0
      else
        return 1
      fi
    else
      return 1
    fi
  }
  
  # Try to connect to the URL
  info "Checking if $service_name is accessible at $url"
  local start_time=$(date +%s)
  
  while true; do
    if check_url "$url" "$http_tool"; then
      success "$service_name is accessible at $url"
      return 0
    fi
    
    counter=$((counter + 1))
    
    # Check if we've exceeded the timeout
    local current_time=$(date +%s)
    local elapsed_time=$((current_time - start_time))
    
    if [ $elapsed_time -ge $timeout ]; then
      warning "Timeout waiting for $service_name to be accessible at $url after ${elapsed_time}s"
      return 1
    fi
    
    # Print progress every 5 attempts
    if [ $((counter % 5)) -eq 0 ]; then
      echo -e "${YELLOW}${EMOJI_HOURGLASS}Still waiting for $service_name... (${elapsed_time}s elapsed)${RESET}"
    fi
    
    # Sleep for a shorter interval to be more responsive
    sleep 2
  done
}

# Function to get user input without interference from trap messages
get_user_input() {
  local prompt=$1
  local default=$2
  local response
  
  # Temporarily disable the ALRM trap and save the old trap
  local old_trap
  old_trap=$(trap -p ALRM | sed -e "s/^trap -- '\(.*\)' ALRM$/\1/")
  trap '' ALRM
  
  # First echo the prompt (don't use printf as it might be causing issues)
  echo -en "$prompt"
  
  # Read the input separately
  read response
  
  # Re-enable the original ALRM trap
  trap "$old_trap" ALRM
  
  # Return the response or default
  if [ -z "$response" ]; then
    echo "$default"
  else
    # Only trim whitespace, don't remove all spaces
    response=$(echo "$response" | xargs)
    echo "$response"
  fi
}

# Improved function to get user input more reliably and consistently
get_input() {
  local prompt=$1
  local default=$2
  local response
  
  # Display a clear user input marker
  echo -e "\n${BOLD}${WHITE}========== USER INPUT REQUIRED ===========${RESET}"
  
  # Temporarily disable the ALRM trap to prevent interruptions
  local old_trap
  old_trap=$(trap -p ALRM | sed -e "s/^trap -- '\(.*\)' ALRM$/\1/")
  trap '' ALRM
  
  # Display the prompt with the default value
  echo -en "${BOLD}${CYAN}>>> $prompt${RESET} [${default}]: "
  
  # Read the input
  read response
  
  # Re-enable the original ALRM trap
  trap "$old_trap" ALRM
  
  # Use default if no input provided
  if [ -z "$response" ]; then
    echo "$default"
  else
    # Trim whitespace but preserve internal spaces
    response=$(echo "$response" | xargs)
    echo "$response"
  fi
}

# Function to consolidate service configuration steps
configure_service() {
  local service=$1
  local container=$2
  local config_script=$3
  local env_vars=$4  # Optional additional environment variables
  
  print_step "Configuring $service"
  show_progress "Setting up $service configuration..."
  
  # Verify the script exists
  if [ ! -f "$config_script" ]; then
    warning "$service configuration script not found at $config_script"
    return 1
  fi
  
  # Make the script executable
  chmod +x "$config_script"
  
  # Execute the configuration script with environment variables
  if [ -n "$env_vars" ]; then
    eval "$env_vars $config_script"
  else
    # Pass container name as environment variable
    if [ -n "$container" ]; then
      eval "${service^^}_CONTAINER=$container $config_script"
    else
      "$config_script"
    fi
  fi
  
  # Check the result
  local result=$?
  if [ $result -eq 0 ]; then
    success "$service configuration completed successfully"
    return 0
  else
    warning "$service configuration encountered issues. Exit code: $result"
    return $result
  fi
}

# Print important settings
print_step "Setup Configuration"
echo -e "${BOLD}Environment Settings:${RESET}"
echo -e "  ${BOLD}Skip URL Checks:${RESET} ${SKIP_URL_CHECKS}"
echo -e "  ${BOLD}Skip Protocol Detection:${RESET} ${SKIP_PROTOCOL_DETECTION}"
echo -e "  ${BOLD}Skip API Check:${RESET} ${SKIP_API_CHECK}"
echo -e "  ${BOLD}Fast Setup:${RESET} ${FAST_SETUP}"
echo -e "  ${BOLD}Debug Mode:${RESET} ${DEBUG}"

# Check requirements
print_header "Checking System Requirements"
show_progress "Verifying installed dependencies..."

if ! command_exists docker; then
  error "Docker is not installed. Please install Docker first."
  exit 1
fi
success "Docker is installed"

if ! command_exists docker-compose; then
  error "docker-compose is not installed. Please install docker-compose first."
  exit 1
fi
success "Docker Compose is installed"

if ! command_exists curl; then
  warning "curl is not installed. This script uses curl for testing."
  read -p "Continue without curl? (y/n) " CONTINUE_WITHOUT_CURL
  if [[ $CONTINUE_WITHOUT_CURL != "y" && $CONTINUE_WITHOUT_CURL != "Y" ]]; then
    error "Exiting. Please install curl and try again."
    exit 1
  fi
else
  success "curl is installed"
fi

# Ask for environment
print_header "Environment Selection"
echo -e "Please select the environment to set up:"
echo -e "  ${CYAN}1.${RESET} Development ${YELLOW}(default)${RESET}"
echo -e "  ${CYAN}2.${RESET} Staging"
echo -e "  ${CYAN}3.${RESET} Production"
echo

# Print a highly visible input request marker
echo -e "\n${BOLD}${WHITE}========== USER INPUT REQUIRED ===========${RESET}"

# Display the prompt separately to avoid it being read as part of the input
echo -en "${BOLD}${CYAN}>>> Please make a selection:${RESET} ${BOLD}Enter your choice [1]${RESET}: "

# Read user input directly - note we just pass empty strings as we've already displayed the prompt
read ENV_CHOICE

# Use default if empty
if [ -z "$ENV_CHOICE" ]; then
  ENV_CHOICE="1"
fi

# Debug line to see what's actually captured
debug "User selected option: '$ENV_CHOICE'"

# Make sure to sanitize the input to prevent unexpected values
ENV_CHOICE=$(echo "$ENV_CHOICE" | tr -d '[:space:]')

case $ENV_CHOICE in
  1|"")
    ENVIRONMENT="dev"
    ENV_DISPLAY="Development"
    ;;
  2)
    ENVIRONMENT="staging"
    ENV_DISPLAY="Staging"
    ;;
  3)
    ENVIRONMENT="prod"
    ENV_DISPLAY="Production"
    ;;
  *)
    echo -e "${YELLOW}${EMOJI_WARNING} WARNING: Invalid choice '${ENV_CHOICE}'.${RESET}"
    echo -e "Defaulting to development environment."
    ENVIRONMENT="dev"
    ENV_DISPLAY="Development"
    ;;
esac

export ENVIRONMENT
success "Using ${BOLD}$ENV_DISPLAY${RESET} environment"

# If environment selection was successful, continue
if [ -n "$ENVIRONMENT" ]; then
  success "Using $ENVIRONMENT environment"
  
  # Fix template files to ensure proper quoting
  fix_template_files() {
    print_step "Fixing configuration templates"
    show_progress "Ensuring proper quoting in template files..."
    
    # Check if env.template.j2 exists
    if [ -f "config/templates/env.template.j2" ]; then
      # Make a backup
      cp config/templates/env.template.j2 config/templates/env.template.j2.bak
      
      # Ensure KEYCLOAK_SECURITY_HEADERS is properly quoted in the template
      if ! grep -q 'KEYCLOAK_SECURITY_HEADERS="' config/templates/env.template.j2; then
        # Add the properly quoted line to the template
        echo 'KEYCLOAK_SECURITY_HEADERS="Strict-Transport-Security:max-age=31536000; includeSubDomains,X-XSS-Protection:1; mode=block,X-Content-Type-Options:nosniff,X-Frame-Options:SAMEORIGIN"' > config/templates/env.template.j2.new
        cat config/templates/env.template.j2 >> config/templates/env.template.j2.new
        mv config/templates/env.template.j2.new config/templates/env.template.j2
        success "Fixed KEYCLOAK_SECURITY_HEADERS quoting in template"
      else
        info "KEYCLOAK_SECURITY_HEADERS already properly quoted in template"
      fi
      
      # Ensure GLOBAL_SECURITY_HEADERS is properly quoted in the template
      if ! grep -q 'GLOBAL_SECURITY_HEADERS="' config/templates/env.template.j2; then
        # Add the properly quoted line to the template
        echo 'GLOBAL_SECURITY_HEADERS="X-Frame-Options:SAMEORIGIN,X-XSS-Protection:1; mode=block,X-Content-Type-Options:nosniff,Referrer-Policy:strict-origin"' >> config/templates/env.template.j2
        success "Fixed GLOBAL_SECURITY_HEADERS quoting in template"
      else
        info "GLOBAL_SECURITY_HEADERS already properly quoted in template"
      fi
    else
      warning "env.template.j2 not found at expected location"
    fi
  }
  
  # Run the template fix function before generating configuration
  fix_template_files
  
  print_step "Generating Configuration for $ENVIRONMENT Environment"
  
  # Generate configuration
  show_progress "Running configuration generator..."
  "$SCRIPT_DIR/generate-config.sh"
  success "Configuration generated successfully"
  
  # TODO: The check_and_update_core_files function will be implemented in a separate PR
  # Check and update core files
  # check_and_update_core_files
  
  # Check if hosts file needs to be updated (only for staging/production)
  if [ "$ENVIRONMENT" != "dev" ]; then
    print_step "Checking Host Configuration"
    
    # Detect the base domain from the .env file
    BASE_DOMAIN=$(grep "BASE_DOMAIN=" .env | cut -d '=' -f2)
    
    if grep -q "$BASE_DOMAIN" /etc/hosts; then
      success "Host entries for $BASE_DOMAIN already exist in /etc/hosts"
    else
      warning "You need to update your /etc/hosts file to include entries for $BASE_DOMAIN"
      echo "This requires administrator privileges."
      echo -e "${BOLD}Sample entries to add:${RESET}"
      echo "127.0.0.1 $(grep "FRONTEND_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
      echo "127.0.0.1 $(grep "API_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
      echo "127.0.0.1 $(grep "KEYCLOAK_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
      
      # Print a highly visible input request marker
      echo -e "\n${BOLD}${WHITE}========== USER INPUT REQUIRED ===========${RESET}"
      
      # Display the prompt separately to avoid it being read as part of the input
      echo -en "${BOLD}${CYAN}>>> Host File Configuration:${RESET} ${BOLD}Would you like to update /etc/hosts automatically? (y/n)${RESET} "

      # Read user input directly
      read UPDATE_HOSTS

      # Use default if empty
      if [ -z "$UPDATE_HOSTS" ]; then
        UPDATE_HOSTS="n"
      fi

      if [[ $UPDATE_HOSTS == "y" || $UPDATE_HOSTS == "Y" ]]; then
        echo -e "${BOLD}The following entries will be added to /etc/hosts:${RESET}"
        echo "127.0.0.1 $(grep "FRONTEND_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        echo "127.0.0.1 $(grep "API_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        echo "127.0.0.1 $(grep "KEYCLOAK_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        echo "127.0.0.1 $(grep "KONG_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        echo "127.0.0.1 $(grep "GRAFANA_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        echo "127.0.0.1 $(grep "PROMETHEUS_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN"
        
        show_progress "Updating /etc/hosts (you may be prompted for your password)..."
        sudo bash -c "cat >> /etc/hosts << EOF
# DIVE25 Domains
127.0.0.1 $(grep "FRONTEND_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "API_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "KEYCLOAK_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "KONG_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "GRAFANA_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "PROMETHEUS_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "MONGODB_EXPRESS_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "PHPLDAPADMIN_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
127.0.0.1 $(grep "OPA_DOMAIN=" .env | cut -d '=' -f2).$BASE_DOMAIN
EOF"
        success "Host file updated successfully"
      else
        warning "Please update your /etc/hosts file manually before continuing."
      fi
    fi
  fi
  
  # Function to check if mkcert is installed
  check_mkcert_installed() {
    if ! command -v mkcert &> /dev/null; then
      error "mkcert is not installed. Please install it first."
      info "Installation instructions: https://github.com/FiloSottile/mkcert#installation"
      exit 1
    fi
  }
  
  # Function to check certificate expiration (returns 0 if cert is valid, 1 if expired or will expire soon)
  check_certificate_expiration() {
    local cert_path=$1
    local days_threshold=${2:-30}  # Default to 30 days threshold
    
    if [ ! -f "$cert_path" ]; then
      return 1
    fi
    
    # Get expiration date in seconds since epoch
    local expiry_date=$(openssl x509 -enddate -noout -in "$cert_path" | sed -e 's/notAfter=//')
    local expiry_seconds=$(date -j -f "%b %d %H:%M:%S %Y %Z" "$expiry_date" +%s 2>/dev/null)
    
    if [ $? -ne 0 ]; then
      # Try alternative date format for Linux
      expiry_seconds=$(date -d "$expiry_date" +%s 2>/dev/null)
      if [ $? -ne 0 ]; then
        warning "Could not parse certificate expiration date. Assuming certificate needs renewal."
        return 1
      fi
    fi
    
    local current_seconds=$(date +%s)
    local threshold_seconds=$((days_threshold * 86400))
    
    # Check if certificate is expired or will expire soon
    if [ $((expiry_seconds - current_seconds)) -lt $threshold_seconds ]; then
      return 1
    fi
    
    return 0
  }
  
  # Function to check if certificate is issued by mkcert
  is_mkcert_certificate() {
    local cert_path=$1
    
    if [ ! -f "$cert_path" ]; then
      return 1
    fi
    
    # Check if certificate issuer contains "mkcert"
    if openssl x509 -issuer -noout -in "$cert_path" | grep -i "mkcert" > /dev/null; then
      return 0
    fi
    
    return 1
  }
  
  # Function to generate certificates using mkcert
  generate_mkcert_certificates() {
    local cert_path=$1
    local key_path=$2
    local domains=("${@:3}")
    
    check_mkcert_installed
    
    local cert_dir=$(dirname "$cert_path")
    if [ ! -d "$cert_dir" ]; then
      mkdir -p "$cert_dir"
      info "Created directory: $cert_dir"
    fi
    
    show_progress "Generating certificates using mkcert..."
    
    # Create domain list for mkcert
    local domain_list=""
    for domain in "${domains[@]}"; do
      domain_list="$domain_list $domain"
    done
    
    # Generate certificate
    mkcert -cert-file "$cert_path" -key-file "$key_path" $domain_list
    
    if [ $? -eq 0 ]; then
      success "Certificates generated successfully at:\n  - $cert_path\n  - $key_path"
      
      # Create symbolic links for compatibility
      ln -sf $(basename "$cert_path") "$cert_dir/dive25-cert.pem"
      ln -sf $(basename "$key_path") "$cert_dir/dive25-key.pem"
      ln -sf "dive25-cert.pem" "$cert_dir/tls.crt"
      ln -sf "dive25-key.pem" "$cert_dir/tls.key"
      
      # Copy mkcert root CA to Kong's trusted certs
      copy_mkcert_ca_to_kong
      
      return 0
    else
      error "Failed to generate certificates"
      return 1
    fi
  }
  
  # Function to copy mkcert root CA to Kong's trusted certs
  copy_mkcert_ca_to_kong() {
    local kong_certs_dir="./kong/ssl"
    local ca_cert_path="$kong_certs_dir/ca-certificates.crt"
    local mkcert_root_ca=""
    
    # Find mkcert root CA location based on OS
    if [ "$(uname)" == "Darwin" ]; then
      mkcert_root_ca="$HOME/Library/Application Support/mkcert/rootCA.pem"
    elif [ "$(uname)" == "Linux" ]; then
      mkcert_root_ca="$HOME/.local/share/mkcert/rootCA.pem"
    else
      warning "Unknown OS, can't determine mkcert root CA location"
      return 1
    fi
    
    if [ ! -f "$mkcert_root_ca" ]; then
      warning "mkcert root CA not found at $mkcert_root_ca"
      return 1
    fi
    
    # Ensure Kong certs directory exists
    if [ ! -d "$kong_certs_dir" ]; then
      mkdir -p "$kong_certs_dir"
    fi
    
    # Create combined CA certificate file
    if [ -f "$ca_cert_path" ]; then
      # Check if mkcert CA is already in the file
      if grep -q "mkcert development CA" "$ca_cert_path"; then
        info "mkcert root CA already in Kong's trusted certificates"
      else
        show_progress "Adding mkcert root CA to Kong's trusted certificates..."
        cat "$mkcert_root_ca" >> "$ca_cert_path"
        success "Added mkcert root CA to Kong's trusted certificates"
      fi
    else
      show_progress "Creating Kong's trusted certificates with mkcert root CA..."
      cp "$mkcert_root_ca" "$ca_cert_path"
      success "Created Kong's trusted certificates with mkcert root CA"
    fi
    
    return 0
  }
  
  # Check if SSL certificates exist
  print_step "Checking SSL Certificates"
  SSL_CERT_PATH=$(grep "SSL_CERT_PATH=" .env | cut -d '=' -f2)
  SSL_KEY_PATH=$(grep "SSL_KEY_PATH=" .env | cut -d '=' -f2)
  
  NEED_NEW_CERTS=false
  
  if [ "$USE_HTTPS" = "true" ]; then
    if [ ! -f "$SSL_CERT_PATH" ] || [ ! -f "$SSL_KEY_PATH" ]; then
      warning "SSL certificates not found at: \n  - $SSL_CERT_PATH\n  - $SSL_KEY_PATH"
      NEED_NEW_CERTS=true
    elif ! is_mkcert_certificate "$SSL_CERT_PATH"; then
      warning "Existing certificates are not generated by mkcert."
      warning "For consistency, we should replace them with mkcert certificates."
      NEED_NEW_CERTS=true
    elif ! check_certificate_expiration "$SSL_CERT_PATH" 30; then
      warning "SSL certificate is expired or will expire within 30 days."
      NEED_NEW_CERTS=true
    else
      success "SSL certificates are valid and generated by mkcert"
      # Even for valid certificates, we should ensure Kong trusts the mkcert root CA
      copy_mkcert_ca_to_kong
    fi
    
    if [ "$NEED_NEW_CERTS" = true ]; then
      # Print a highly visible input request marker
      echo -e "\n${BOLD}${WHITE}========== USER INPUT REQUIRED ===========${RESET}"
      
      # Display the prompt separately to avoid it being read as part of the input
      echo -en "${BOLD}${CYAN}>>> SSL Certificate Configuration:${RESET} ${BOLD}Would you like to generate certificates using mkcert? (y/n)${RESET} "

      # Read user input directly
      read GENERATE_CERTS

      # Use default if empty
      if [ -z "$GENERATE_CERTS" ]; then
        GENERATE_CERTS="y"  # Default to yes for better user experience
      fi

      if [[ $GENERATE_CERTS == "y" || $GENERATE_CERTS == "Y" ]]; then
        # Generate certificates for all domains
        generate_mkcert_certificates "$SSL_CERT_PATH" "$SSL_KEY_PATH" \
          "*.$BASE_DOMAIN" "$BASE_DOMAIN" \
          "frontend.$BASE_DOMAIN" "api.$BASE_DOMAIN" "keycloak.$BASE_DOMAIN" \
          "grafana.$BASE_DOMAIN" "prometheus.$BASE_DOMAIN" "kong.$BASE_DOMAIN" \
          "opa.$BASE_DOMAIN" "mongo-express.$BASE_DOMAIN" "phpldapadmin.$BASE_DOMAIN"
      else
        warning "Please provide mkcert SSL certificates before continuing if using HTTPS."
      fi
    fi
  else
    info "HTTPS is disabled. No SSL certificates needed."
  fi
  
  # Add a function to check for stalled docker processes
  check_stalled_docker_processes() {
    print_step "Checking for stalled Docker processes"
    
    # Check if any containers are in a 'created' or 'restarting' state
    local stalled_containers=$(docker ps -a --filter "status=created" --filter "status=restarting" --format "{{.ID}}")
    
    if [ -n "$stalled_containers" ]; then
      warning "Found stalled containers that might block startup. Removing them..."
      
      for container_id in $stalled_containers; do
        local container_name=$(docker inspect --format '{{.Name}}' "$container_id" | sed 's/^\///')
        warning "Removing stalled container: $container_name ($container_id)"
        docker rm -f "$container_id" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
          success "Successfully removed stalled container: $container_name"
        else
          error "Failed to remove stalled container: $container_name"
        fi
      done
    else
      success "No stalled containers found"
    fi
    
    # Check for hanging docker networks
    local networks=$(docker network ls --filter "driver=bridge" --format "{{.Name}}" | grep -E 'dive25|keycloak' || true)
    
    if [ -n "$networks" ]; then
      info "Checking existing Docker networks for orphaned containers..."
      
      for network in $networks; do
        local network_containers=$(docker network inspect "$network" --format '{{range .Containers}}{{.Name}} {{end}}' | tr ' ' '\n' | grep -v '^$')
        local network_container_count=$(echo "$network_containers" | grep -v '^$' | wc -l)
        
        if [ "$network_container_count" -eq 0 ]; then
          warning "Found orphaned network with no containers: $network"
          show_progress "Removing orphaned network: $network"
          docker network rm "$network" > /dev/null 2>&1 || warning "Could not remove network: $network"
        else
          debug "Network $network has $network_container_count containers, keeping it"
        fi
      done
    fi
    
    success "Docker environment cleanup completed"
  }
  
  # Stop existing containers
  print_step "Stopping Existing Containers"
  show_progress "Bringing down any running containers..."
  docker-compose down
  
  # Check for and clean up stalled docker processes
  check_stalled_docker_processes
  
  # Check if there are still any containers with names matching our pattern
  # Get the project prefix dynamically
  project_prefix=$(docker-compose config --services 2>/dev/null | head -n 1 | grep -o "^[a-zA-Z0-9]*" || echo "dive25")
  if docker ps -a | grep -q "${project_prefix}-"; then
    warning "Some containers are still present. Forcefully removing them..."
    docker ps -a | grep "${project_prefix}-" | awk '{print $1}' | xargs -r docker rm -f
    success "Removed leftover containers"
  fi
  
  # Start containers
  print_header "Starting Containers"
  show_progress "Launching containers with the new configuration..."
  echo -e "${YELLOW}${EMOJI_INFO}This may take a while (especially on first run)...${RESET}"
  
  # Function to check and build necessary Docker images
  check_and_build_images() {
    print_step "Checking and Building Docker Images"
    
    # Check for the frontend image
    if ! docker images | grep -q "dive-mvp-frontend"; then
      show_progress "Building frontend Docker image..."
      
      if [ -f "frontend/Dockerfile" ]; then
        # Build the frontend image
        docker build -t dive-mvp-frontend:latest -f frontend/Dockerfile frontend/ || true
        
        if [ $? -eq 0 ]; then
          success "Frontend Docker image built successfully"
        else
          warning "Failed to build frontend Docker image. Will attempt to continue with deployment."
        fi
      else
        warning "Frontend Dockerfile not found at frontend/Dockerfile. Check your project structure."
      fi
    else
      info "Frontend Docker image already exists"
    fi
    
    # Check for the API image
    if ! docker images | grep -q "dive-mvp-api"; then
      show_progress "Building API Docker image..."
      
      if [ -f "api/Dockerfile" ]; then
        # Build the API image
        docker build -t dive-mvp-api:latest -f api/Dockerfile api/ || true
        
        if [ $? -eq 0 ]; then
          success "API Docker image built successfully"
        else
          warning "Failed to build API Docker image. Will attempt to continue with deployment."
        fi
      else
        warning "API Dockerfile not found at api/Dockerfile. Check your project structure."
      fi
    else
      info "API Docker image already exists"
    fi
  }
  
  # Check and build necessary Docker images before trying to start containers
  check_and_build_images
  
  # Create a log file for detailed docker-compose output
  COMPOSE_LOG_FILE="/tmp/dive25-compose-$(date +%s).log"
  touch $COMPOSE_LOG_FILE
  info "Detailed startup logs will be saved to: $COMPOSE_LOG_FILE"
  
  # Force pull newest images to avoid inconsistent state
  show_progress "Pulling latest Docker images..."
  docker-compose pull > /dev/null 2>&1 || warning "Failed to pull some images. Will use local images if available."
  
  # Completely replace the docker-compose startup approach
  COMPOSE_TIMEOUT=300 # 5 minutes
  show_progress "Running docker-compose up with ${COMPOSE_TIMEOUT}s timeout..."
  
  # Run the docker-compose command directly - no background processing
  info "Starting containers with command: docker-compose up -d --remove-orphans"
  echo "Command output will be saved to: $COMPOSE_LOG_FILE"
  
  # Direct approach - run in foreground with timeout
  if command -v timeout >/dev/null 2>&1; then
    # System has timeout command
    # On macOS, the BSD timeout might behave differently than GNU timeout
    if [ "$(uname)" == "Darwin" ]; then
      # Try with gtimeout from coreutils if available
      if command -v gtimeout >/dev/null 2>&1; then
        gtimeout $COMPOSE_TIMEOUT docker-compose up -d --remove-orphans > $COMPOSE_LOG_FILE 2>&1 || true
      else
        # Fallback to docker-compose without timeout on macOS
        warning "gtimeout command not found on macOS, running docker-compose without timeout"
        docker-compose up -d --remove-orphans > $COMPOSE_LOG_FILE 2>&1 || true
      fi
    else
      # Linux/others - use standard timeout
      timeout $COMPOSE_TIMEOUT docker-compose up -d --remove-orphans > $COMPOSE_LOG_FILE 2>&1 || true
    fi
    compose_exit=$?
  else 
    # No timeout command, run directly
    docker-compose up -d --remove-orphans > $COMPOSE_LOG_FILE 2>&1 || true
    compose_exit=$?
  fi
  
  # Debug info
  info "Docker-compose exit code: $compose_exit"
  
  # If compose failed or timed out, show the tail of the logs
  if [ "$compose_exit" -ne 0 ]; then
    warning "Docker-compose command exited with code $compose_exit. This could be a timeout or an error."
    echo "Last 20 lines of docker-compose output:"
    tail -n 20 $COMPOSE_LOG_FILE
    
    # Try to continue anyway - the containers might still be starting
    warning "Attempting to continue despite docker-compose exit code"
  fi
  
  # Check if container startup was successful by examining actual container status
  actual_running_containers=$(docker ps --format '{{.Names}}' | wc -l | tr -d ' ')
  info "Running containers after docker-compose: $actual_running_containers"
  
  # Wait a bit longer for containers to stabilize - they might still be starting up
  show_progress "Waiting 10 seconds for containers to stabilize..."
  sleep 10
  
  # Check again after waiting, with more detailed info
  actual_running_containers=$(docker ps --format '{{.Names}}' | wc -l | tr -d ' ')
  info "Running containers after waiting: $actual_running_containers"
  
  # Show a list of running containers for debugging
  if [ $actual_running_containers -gt 0 ]; then
    show_progress "Currently running containers:"
    docker ps --format "{{.Names}}: {{.Status}}"
  else
    warning "No containers are running."
    # Capture exit codes of services
    show_progress "Checking service exit status..."
    docker-compose ps
  fi
  
  # Show container status
  show_container_summary
  
  # If no containers are running, output more debug info
  if [ "$actual_running_containers" -eq 0 ]; then
    warning "No containers are running. Checking docker-compose logs for errors..."
    tail -n 50 $COMPOSE_LOG_FILE | grep -i "error\|failed\|exited"
    
    # Try to see if any containers started and then stopped
    info "Checking for recently exited containers..."
    docker ps -a --filter "status=exited" --format "{{.Names}} - {{.Status}}" | head -n 10
    
    # Try cleanup and restart
    cleanup_docker_remnants
    
    # Check again
    actual_running_containers=$(docker-compose ps --services --filter "status=running" 2>/dev/null | wc -l | tr -d ' ')
    info "Running containers after cleanup and restart attempt: $actual_running_containers"
    
    # Collect diagnostics
    collect_diagnostic_info
  fi
  
  # Clean up old log files (keep last 5)
  find /tmp -name "dive25-compose-*.log" -type f -mtime +1 -delete 2>/dev/null || true
  
  # Configure OpenLDAP with initial data
  print_step "Setting up OpenLDAP"
  info "Setting up LDAP directory structure, security groups, and users..."
  
  # Get container name for OpenLDAP - FIXED: Use the actual container name from docker ps
  OPENLDAP_CONTAINER=$(docker ps | grep openldap | awk '{print $NF}')
  if [ -z "$OPENLDAP_CONTAINER" ]; then
    # Fallback to the old method if the direct grep fails
    OPENLDAP_CONTAINER=$(get_container_name "openldap")
  fi
  info "Using OpenLDAP container: ${BOLD}$OPENLDAP_CONTAINER${RESET}"
  
  # Wait for OpenLDAP to be healthy
  show_progress "Waiting for OpenLDAP to be ready..."
  LDAP_MAX_RETRIES=10
  LDAP_RETRY_INTERVAL=5
  LDAP_RETRY_COUNT=0
  
  while [ $LDAP_RETRY_COUNT -lt $LDAP_MAX_RETRIES ]; do
    if docker exec $OPENLDAP_CONTAINER ldapsearch -x -H ldap://localhost:389 -D "cn=admin,dc=dive25,dc=local" -w admin_password -b "dc=dive25,dc=local" > /dev/null 2>&1; then
      success "OpenLDAP is ready and responding to queries!"
      break
    fi
    
    echo -e "${YELLOW}${EMOJI_HOURGLASS}OpenLDAP not ready yet, retrying in ${LDAP_RETRY_INTERVAL} seconds... (Attempt ${LDAP_RETRY_COUNT+1}/${LDAP_MAX_RETRIES})${RESET}"
    sleep $LDAP_RETRY_INTERVAL
    LDAP_RETRY_COUNT=$((LDAP_RETRY_COUNT+1))
  done
  
  if [ $LDAP_RETRY_COUNT -eq $LDAP_MAX_RETRIES ]; then
    warning "OpenLDAP did not respond after $LDAP_MAX_RETRIES attempts. Continuing anyway, but LDAP may not be properly configured."
  else
    # First, ensure the standard schemas are loaded and visible
    show_progress "Verifying and loading standard schemas (cosine, nis, inetOrgPerson)..."
    
    # Load standard schemas first to ensure inetOrgPerson is available for custom schemas
    docker exec $OPENLDAP_CONTAINER bash -c 'cd /etc/ldap/schema && \
      ldapadd -Y EXTERNAL -H ldapi:/// -f cosine.ldif || true && \
      ldapadd -Y EXTERNAL -H ldapi:/// -f nis.ldif || true && \
      ldapadd -Y EXTERNAL -H ldapi:/// -f inetorgperson.ldif || true' > /dev/null 2>&1
    success "Standard schemas loaded or already present"
    
    # Create the base organizational structure first, in the correct hierarchy
    show_progress "Creating basic LDAP structure..."
    
    # Create base DN if it doesn't exist
    docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: dc=dive25,dc=local
objectClass: top
objectClass: dcObject
objectClass: organization
o: DIVE25 Organization
dc: dive25
EOF
    
    # Create users OU
    docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: ou=users,dc=dive25,dc=local
objectClass: top
objectClass: organizationalUnit
ou: users
EOF
    
    # Create security OU
    docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: ou=security,dc=dive25,dc=local
objectClass: top
objectClass: organizationalUnit
ou: security
EOF
    
    # Create clearances OU (child of security)
    docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: ou=clearances,ou=security,dc=dive25,dc=local
objectClass: top
objectClass: organizationalUnit
ou: clearances
EOF
    
    success "Base LDAP structure created"
    
    # Verify the structure exists before proceeding
    if docker exec $OPENLDAP_CONTAINER ldapsearch -x -H ldap://localhost:389 -D "cn=admin,dc=dive25,dc=local" -w admin_password -b "ou=clearances,ou=security,dc=dive25,dc=local" > /dev/null 2>&1; then
      success "Verified clearances OU exists"
    else
      warning "Clearances OU structure verification failed. Bootstrap may encounter errors."
    fi
    
    # Check for setup.sh script in the container - if it exists, run it
    if docker exec $OPENLDAP_CONTAINER ls /container/service/slapd/assets/config/bootstrap/setup.sh &>/dev/null; then
      show_progress "Found bootstrap setup.sh script in container, running it..."
      # Run the script but ignore the errors about entries already existing
      docker exec $OPENLDAP_CONTAINER bash /container/service/slapd/assets/config/bootstrap/setup.sh || true
    elif [ -f "${PROJECT_ROOT}/openldap/setup.sh" ]; then
      show_progress "Found openldap/setup.sh script in project, running it..."
      # Make sure the script is executable
      chmod +x "${PROJECT_ROOT}/openldap/setup.sh"
      # Run the script with OPENLDAP_CONTAINER variable
      OPENLDAP_CONTAINER=$OPENLDAP_CONTAINER "${PROJECT_ROOT}/openldap/setup.sh" || true
    else
      # If neither exists, run the bootstrap script that comes with the container
      show_progress "Running built-in bootstrap configuration..."
      docker exec $OPENLDAP_CONTAINER bash -c "[ -f /container/service/slapd/assets/config/bootstrap/ldif/custom/bootstrap.ldif ] && \
        ldapadd -x -D cn=admin,dc=dive25,dc=local -w admin_password -f /container/service/slapd/assets/config/bootstrap/ldif/custom/bootstrap.ldif" || true
    fi
    
    # Verify the organizational structure exists after bootstrap and create fallback users if needed
    show_progress "Verifying LDAP structure post-bootstrap..."
    
    # Check if admin user exists - if not, create it
    if ! docker exec $OPENLDAP_CONTAINER ldapsearch -x -H ldap://localhost:389 -D "cn=admin,dc=dive25,dc=local" -w admin_password -b "uid=admin,ou=users,dc=dive25,dc=local" > /dev/null 2>&1; then
      show_progress "Creating admin user..."
      # Create admin user manually to ensure it exists
      docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: uid=admin,ou=users,dc=dive25,dc=local
objectClass: top
objectClass: person
objectClass: organizationalPerson
objectClass: inetOrgPerson
uid: admin
sn: Administrator
givenName: System
cn: System Administrator
mail: admin@dive25.local
userPassword: admin
EOF
      success "Admin user created successfully"
    else
      info "Admin user already exists"
    fi
    
    # Check if unclassified clearance exists - if not, create it
    if ! docker exec $OPENLDAP_CONTAINER ldapsearch -x -H ldap://localhost:389 -D "cn=admin,dc=dive25,dc=local" -w admin_password -b "cn=unclassified,ou=clearances,ou=security,dc=dive25,dc=local" > /dev/null 2>&1; then
      show_progress "Creating unclassified security clearance..."
      # Create unclassified clearance manually to ensure it exists
      docker exec $OPENLDAP_CONTAINER ldapadd -x -D "cn=admin,dc=dive25,dc=local" -w admin_password << EOF > /dev/null 2>&1 || true
dn: cn=unclassified,ou=clearances,ou=security,dc=dive25,dc=local
objectClass: top
objectClass: groupOfNames
cn: unclassified
member: uid=admin,ou=users,dc=dive25,dc=local
EOF
      success "Unclassified clearance created successfully"
    else
      info "Unclassified clearance already exists"
    fi
    
    success "OpenLDAP bootstrap and verification completed!"
  fi
  
  # Final verification of LDAP structure
  if docker exec $OPENLDAP_CONTAINER ldapsearch -x -H ldap://localhost:389 -D "cn=admin,dc=dive25,dc=local" -w admin_password -b "dc=dive25,dc=local" > /dev/null 2>&1; then
    success "OpenLDAP structure verified"
  else
    error "OpenLDAP structure could not be verified. LDAP may not be properly configured."
  fi
  
  # Print note about keycloak-config behavior
  echo
  echo -e "${BLUE}${EMOJI_INFO}${BOLD}Note about Keycloak Configuration:${RESET}"
  echo -e "${BLUE}  ‚Ä¢ The keycloak-config container is designed to exit with code 0 after successful configuration."
  echo -e "  ‚Ä¢ This is normal behavior and does not indicate a problem with your deployment."
  echo -e "  ‚Ä¢ You may see it listed as 'exited (0)' in docker-compose ps output.${RESET}"
  echo
  
  # Wait for Keycloak to be available
  print_step "Configuring Keycloak"
  wait_for_service "Keycloak" "https://keycloak.${BASE_DOMAIN}:8443/admin/" 300
  
  # Once Keycloak is ready, run the configuration script
  if [ $? -eq 0 ]; then
    show_progress "Setting up Keycloak configuration..."
    
    # Get container name for Keycloak - store it in a variable for consistent use
    KEYCLOAK_CONTAINER=$(get_container_name "keycloak")
    # Also try direct detection for Keycloak container
    if [ -z "$KEYCLOAK_CONTAINER" ] || ! docker ps | grep -q "$KEYCLOAK_CONTAINER"; then
      # Try alternate detection methods
      KEYCLOAK_CONTAINER=$(docker ps | grep -E 'keycloak|jboss/keycloak' | grep -v "keycloak-config" | awk '{print $NF}' | head -n 1)
    fi
    
    # If still not found, try common names
    if [ -z "$KEYCLOAK_CONTAINER" ] || ! docker ps | grep -q "$KEYCLOAK_CONTAINER"; then
      for possible_name in "keycloak" "postgres-keycloak" "dive25-keycloak" "dive25_keycloak"; do
        if docker ps | grep -q "$possible_name"; then
          KEYCLOAK_CONTAINER="$possible_name"
          break
        fi
      done
    fi
    
    info "Using Keycloak container: ${BOLD}$KEYCLOAK_CONTAINER${RESET}"
    
    # Verify Keycloak container exists
    if ! docker ps | grep -q "$KEYCLOAK_CONTAINER"; then
      error "Cannot find running Keycloak container. Keycloak configuration will be skipped."
      KEYCLOAK_CONTAINER=""
    fi
    
    # Run the Keycloak configuration script if the container is available
    if [ -n "$KEYCLOAK_CONTAINER" ]; then
      # Add a delay to ensure service is fully started
      show_progress "Adding a short delay to ensure Keycloak is fully initialized..."
      sleep 10
      
      # Execute the Keycloak configuration script
      if [ -f "${PROJECT_ROOT}/keycloak/configure-keycloak.sh" ]; then
        info "Found Keycloak configuration script at ${PROJECT_ROOT}/keycloak/configure-keycloak.sh"
        
        # Make the script executable
        chmod +x "${PROJECT_ROOT}/keycloak/configure-keycloak.sh"
        
        # Run the configuration script
        show_progress "Running Keycloak configuration script..."
        KEYCLOAK_CONTAINER=$KEYCLOAK_CONTAINER OPENLDAP_CONTAINER=$OPENLDAP_CONTAINER "${PROJECT_ROOT}/keycloak/configure-keycloak.sh"
        KEYCLOAK_CONFIG_EXIT=$?
        if [ $KEYCLOAK_CONFIG_EXIT -eq 0 ]; then
          success "Keycloak configuration script executed successfully!"
        else
          warning "Keycloak configuration script encountered issues. Exit code: $KEYCLOAK_CONFIG_EXIT"
        fi

        # Now run the identity provider configuration
        show_progress "Configuring identity providers in Keycloak..."
        keycloak_post_config_hook
        if [ $? -eq 0 ]; then
          success "Identity provider configuration completed successfully!"
        else
          warning "Identity provider configuration encountered issues"
        fi
      else
        warning "Keycloak configuration script not found at ${PROJECT_ROOT}/keycloak/configure-keycloak.sh"
      fi
    else
      warning "Keycloak container not found. Skipping Keycloak configuration."
    fi
  else
    warning "Keycloak is not available. Skipping Keycloak configuration."
  fi
  
  # Configure Kong
  print_step "Configuring Kong API Gateway"
  # Wait for Kong to be available
  wait_for_service "Kong" "https://kong.${BASE_DOMAIN}:8443/status" 300
  
  if [ $? -eq 0 ]; then
    show_progress "Setting up Kong configuration..."
    
    # Get container name for Kong
    KONG_CONTAINER=$(get_container_name "kong")
    if [ -z "$KONG_CONTAINER" ] || ! docker ps | grep -q "$KONG_CONTAINER"; then
      # Try alternate detection
      KONG_CONTAINER=$(docker ps | grep -E 'kong' | grep -v "kong-config" | awk '{print $NF}' | head -n 1)
    fi
    
    info "Using Kong container: ${BOLD}$KONG_CONTAINER${RESET}"
    
    # Verify Kong container exists
    if ! docker ps | grep -q "$KONG_CONTAINER"; then
      error "Cannot find running Kong container. Kong configuration will be skipped."
      KONG_CONTAINER=""
    fi
    
    # Run the Kong configuration script if the container is available
    if [ -n "$KONG_CONTAINER" ]; then
      # Add a delay to ensure service is fully started
      show_progress "Adding a short delay to ensure Kong is fully initialized..."
      sleep 5
      
      # Execute the Kong configuration script
      if [ -f "${PROJECT_ROOT}/kong/kong-configure-unified.sh" ]; then
        info "Found Kong configuration script at ${PROJECT_ROOT}/kong/kong-configure-unified.sh"
        
        # Make sure the script is executable
        chmod +x "${PROJECT_ROOT}/kong/kong-configure-unified.sh"
        
        # Run the configuration script
        show_progress "Running Kong configuration script..."
        KONG_CONTAINER=$KONG_CONTAINER "${PROJECT_ROOT}/kong/kong-configure-unified.sh"
        
        if [ $? -eq 0 ]; then
          success "Kong configuration script executed successfully!"
        else
          warning "Kong configuration script encountered issues. Exit code: $?"
        fi
      else
        warning "Kong configuration script not found at ${PROJECT_ROOT}/kong/kong-configure-unified.sh"
        warning "Kong may not be properly configured."
      fi
    else
      warning "Kong container not found. Skipping Kong configuration."
    fi
  else
    warning "Kong is not available. Skipping Kong configuration."
  fi
  
  # Continue with the rest of the script...
  print_header "Deployment Summary"
  echo -e "${GREEN}${EMOJI_SPARKLES}Setup completed successfully!${EMOJI_SPARKLES}${RESET}"
  echo
  
  # Display elapsed time
  print_elapsed_time $(($(date +%s) - START_TIME))
  
  # Print a summary of what was done
  echo
  echo -e "${BOLD}What was set up:${RESET}"
  echo -e "  ${GREEN}‚úì${RESET} Environment: ${BOLD}$ENV_DISPLAY${RESET}"
  echo -e "  ${GREEN}‚úì${RESET} OpenLDAP Directory Services"
  echo -e "  ${GREEN}‚úì${RESET} Keycloak Identity Provider"
  echo -e "  ${GREEN}‚úì${RESET} API Services"
  echo -e "  ${GREEN}‚úì${RESET} Frontend Application"
  echo -e "  ${GREEN}‚úì${RESET} Kong API Gateway"
  
  # Show connection information
  echo
  echo -e "${BOLD}Connection Information:${RESET}"
  echo -e "  ${BOLD}Frontend:${RESET} https://frontend.${BASE_DOMAIN}:8443"
  echo -e "  ${BOLD}API:${RESET} https://api.${BASE_DOMAIN}:8443"
  echo -e "  ${BOLD}Keycloak:${RESET} https://keycloak.${BASE_DOMAIN}:8443"
  echo -e "  ${BOLD}Kong:${RESET} https://kong.${BASE_DOMAIN}:8443"
  
  # Next steps
  echo
  echo -e "${BOLD}Next Steps:${RESET}"
  echo -e "  1. Access the frontend at ${CYAN}https://frontend.${BASE_DOMAIN}:8443${RESET}"
  echo -e "  2. Login with the default admin user: ${CYAN}admin/admin${RESET}"
  echo -e "  3. Explore the application!"
  
  echo
  echo -e "${BOLD}For troubleshooting, you can view logs with:${RESET}"
  echo -e "  ${CYAN}docker-compose logs -f [service-name]${RESET}"
  
  # Define the show_final_summary function
  show_final_summary() {
    echo
    echo -e "${GREEN}${BOLD}${EMOJI_SPARKLES} DIVE25 Authentication System Setup Complete! ${EMOJI_SPARKLES}${RESET}"
    echo
    echo -e "${BLUE}All services have been configured and are ready to use.${RESET}"
    echo
  }
  
  # Add the final summary
  show_final_summary
  
  # Define apply_frontend_fixes function
  apply_frontend_fixes() {
    print_step "Applying Frontend Fixes"
    
    # Fix the authentication context to handle public routes properly
    if [ -f "frontend/src/context/auth-context.tsx" ]; then
      show_progress "Updating authentication context to handle public routes..."
      
      # Use our portable_sed function
      portable_sed 's|const NON_AUTH_PATHS = .*|const NON_AUTH_PATHS = ['"'"'/'"'"', '"'"'/country-select'"'"', '"'"'/login'"'"'];|g' "frontend/src/context/auth-context.tsx"
      
      success "Updated non-authenticated paths in auth context"
    fi
    
    # Fix the app component to handle Keycloak URLs
    if [ -f "frontend/src/pages/_app.tsx" ]; then
      show_progress "Updating app component to handle Keycloak URLs..."
      
      # Check if the Keycloak paths are already in the file
      if grep -q "router.pathname.includes('/broker/')" "frontend/src/pages/_app.tsx" && \
         grep -q "router.pathname.includes('/realms/')" "frontend/src/pages/_app.tsx"; then
        success "Public page detection in frontend app already includes Keycloak URLs"
      else
        # Create a temporary file with the updated content to avoid quoting issues
        APP_FILE="frontend/src/pages/_app.tsx"
        TMP_FILE="${APP_FILE}.tmp"
        
        # Look for the isPublicPage line and modify it
        if grep -q "const isPublicPage = router.pathname === '/' || router.pathname === '/country-select';" "$APP_FILE"; then
          # Simple single-line version
          portable_sed 's|const isPublicPage = router.pathname === '"'"'/'"'"' || router.pathname === '"'"'/country-select'"'"';|const isPublicPage = router.pathname === '"'"'/'"'"' || router.pathname === '"'"'/country-select'"'"' || router.pathname.includes('"'"'/broker/'"'"') || router.pathname.includes('"'"'/realms/'"'"');|g' "$APP_FILE"
        else
          # Multi-line version - more complex case
          warning "Complex isPublicPage format detected. The file may already have the correct paths."
          info "Current isPublicPage configuration:"
          grep -A 4 "const isPublicPage" "$APP_FILE" || true
        fi
        
        success "Updated public page detection in frontend app"
      fi
    fi
  }
  
  # Define verify_authentication_flow function
  verify_authentication_flow() {
    print_step "Verifying Authentication Flow"
    
    # 1. Check if country selection page is accessible
    local country_select_url="https://frontend.${BASE_DOMAIN}:8443/country-select"
    show_progress "Checking country selection page at $country_select_url..."
    if curl -s -k "$country_select_url" | grep -q "Select Your Country"; then
      success "Country selection page is accessible"
    else
      warning "Country selection page may not be accessible, status code: $(curl -s -k -o /dev/null -w "%{http_code}" "$country_select_url")"
    fi
    
    # 2. Check Keycloak country IdP configuration
    local KEYCLOAK_CONFIG_CONTAINER=$(docker ps -a --format '{{.Names}}' | grep "$KEYCLOAK_CONFIG_CONTAINER_NAME")
    if [ -n "$KEYCLOAK_CONFIG_CONTAINER" ]; then
      show_progress "Checking Keycloak country IdP paths..."
      if docker exec $KEYCLOAK_CONFIG_CONTAINER test -f /opt/keycloak/configure-country-idps.sh; then
        if docker exec $KEYCLOAK_CONFIG_CONTAINER grep -q "/identity-providers/" /opt/keycloak/configure-country-idps.sh; then
          success "Keycloak country IdP configuration is using correct paths"
        else
          warning "Keycloak country IdP configuration may still be using incorrect paths"
        fi
      else
        warning "configure-country-idps.sh not found in Keycloak config container"
      fi
    else
      warning "Keycloak configuration container not found"
    fi
    
    # 3. Check if identity providers are actually configured
    show_progress "Verifying identity providers are configured in Keycloak..."
    if verify_keycloak_identity_providers; then
      success "Identity providers are correctly configured in Keycloak"
    else
      warning "Identity providers may not be correctly configured in Keycloak"
      
      # Attempt to fix by running the configuration script directly
      show_progress "Attempting to fix identity provider configuration..."
      if fix_keycloak_identity_providers; then
        success "Successfully fixed identity provider configuration"
      else
        warning "Could not automatically fix identity provider configuration"
      fi
    fi
    
    success "Authentication flow verification completed"
    echo "Your authentication system has been verified to the extent possible via automated testing."
    echo "For a full end-to-end test, manually navigate to https://frontend.${BASE_DOMAIN}:8443/ in your browser"
    echo "and verify that you can select a country and authenticate through the appropriate identity provider."
  }
  
  # Function to verify that Keycloak identity providers are configured
  verify_keycloak_identity_providers() {
    local KEYCLOAK_CONTAINER=$(docker ps --format '{{.Names}}' | grep 'keycloak' | grep -v 'config')
    
    if [ -z "$KEYCLOAK_CONTAINER" ]; then
      warning "Keycloak container not found"
      return 1
    fi
    
    # First check if the marker file exists
    if docker exec $KEYCLOAK_CONTAINER test -f /tmp/keycloak-config/idps-configured; then
      success "Identity providers are marked as configured"
      return 0
    fi
    
    # If marker doesn't exist, try to get the list of identity providers
    local IDPS=$(docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh config credentials --server http://localhost:8080 --realm master --user admin --password admin 2>/dev/null && \
                 docker exec $KEYCLOAK_CONTAINER /opt/keycloak/bin/kcadm.sh get identity-provider/instances -r dive25 2>/dev/null)
    
    # Check if we have the expected identity providers
    if echo "$IDPS" | grep -q "usa-oidc" && \
       echo "$IDPS" | grep -q "uk-oidc" && \
       echo "$IDPS" | grep -q "canada-oidc" && \
       echo "$IDPS" | grep -q "australia-oidc" && \
       echo "$IDPS" | grep -q "newzealand-oidc"; then
      # Create marker file for future checks
      docker exec $KEYCLOAK_CONTAINER bash -c "mkdir -p /tmp/keycloak-config && touch /tmp/keycloak-config/idps-configured"
      return 0  # All expected identity providers found
    else
      return 1  # Not all expected identity providers were found
    fi
  }
  
  # Function to fix Keycloak identity providers if they're not configured
  fix_keycloak_identity_providers() {
    local KEYCLOAK_CONTAINER=$(docker ps --format '{{.Names}}' | grep 'keycloak' | grep -v 'config')
    
    if [ -z "$KEYCLOAK_CONTAINER" ]; then
      warning "Keycloak container not found"
      return 1
    fi
    
    # Use the keycloak_post_config_hook function to set up the identity providers
    show_progress "Setting up identity providers in Keycloak..."
    keycloak_post_config_hook
    
    # Verify that it worked
    if verify_keycloak_identity_providers; then
      success "Identity provider configuration fix was successful"
      return 0
    else
      warning "Identity provider configuration fix failed"
      return 1
    fi
  }
  
  # Apply frontend fixes
  apply_frontend_fixes
  
  # Verify authentication flow
  verify_authentication_flow
  
  success "Configuration options set for environment: $ENVIRONMENT"
  
  # Function to check and update core source files for authentication flow
  check_and_update_core_files() {
    print_step "Verifying Core Authentication Files"
    
    # 1. Check the Keycloak country IdP configuration file
    show_progress "Checking Keycloak IdP configuration paths..."
    if [ -f "keycloak/configure-country-idps.sh" ]; then
      # Check if the paths are using the wrong directory
      if grep -q "/opt/keycloak/identity-providers" keycloak/configure-country-idps.sh; then
        show_progress "Updating paths in Keycloak IdP configuration..."
        portable_sed 's|/opt/keycloak/identity-providers|/identity-providers|g' "keycloak/configure-country-idps.sh"
        success "Updated paths in Keycloak IdP configuration script"
      else
        success "Keycloak IdP configuration paths are already correct"
      fi
    else
      warning "Keycloak IdP configuration script not found"
    fi
    
    # 2. Check the Auth context in frontend
    show_progress "Checking frontend auth context configuration..."
    local AUTH_CONTEXT_FILE="frontend/src/context/auth-context.tsx"
    if [ -f "$AUTH_CONTEXT_FILE" ]; then
      # Add the proper non-auth paths if not already present
      if ! grep -q "const NON_AUTH_PATHS = \[\'/\', \'/country-select\', \'/login\'\]" "$AUTH_CONTEXT_FILE"; then
        show_progress "Updating non-authenticated paths in auth context..."
        portable_sed 's|const NON_AUTH_PATHS = .*|const NON_AUTH_PATHS = ['\'/\'', '\'/country-select\'', '\'/login\''];|g' "$AUTH_CONTEXT_FILE"
        success "Updated non-authenticated paths in auth context"
      else
        success "Non-authenticated paths already correctly configured"
      fi
      
      # Ensure the useEffect checks for Keycloak URLs
      if ! grep -q "isKeycloakUrl = router.pathname.includes(\'/broker/\') || " "$AUTH_CONTEXT_FILE"; then
        show_progress "Updating authentication initialization logic..."
        # This is a complex change that might be better handled manually if needed
        warning "Authentication initialization logic may need manual review" 
      else
        success "Authentication initialization logic looks correct"
      fi
    else
      warning "Auth context file not found"
    fi
    
    # 3. Check Kong configuration in kong.yml
    show_progress "Checking Kong API Gateway configuration..."
    local KONG_CONFIG_FILE="kong/kong.yml"
    if [ -f "$KONG_CONFIG_FILE" ]; then
      # Check if frontend auth routes include country-select
      if ! grep -q "- /country-select" "$KONG_CONFIG_FILE"; then
        show_progress "Adding /country-select to non-authenticated paths in Kong..."
        # This is a trickier case for portable_sed because of the newline needed
        # We'll handle this separately for each platform
        if [ "$(uname)" == "Darwin" ]; then
          # macOS version
          sed -i '' '/- \/login/a\
          - /country-select' "$KONG_CONFIG_FILE"
        else
          # Linux version
          sed -i '/- \/login/a\        - /country-select' "$KONG_CONFIG_FILE"
        fi
        success "Added /country-select to non-authenticated paths"
      else
        success "Kong configuration has /country-select as a non-authenticated path"
      fi
    else
      warning "Kong configuration file not found"
    fi
  }
  
  print_step "Generating Configuration for $ENVIRONMENT Environment"
fi

# The verify_authentication_flow function is already defined earlier in this script

# Function to check and update core files is defined earlier in the script
# check_and_update_core_files() { ... }

# Add debug info
debug "docker-compose exit code: $compose_exit"

# Function to collect diagnostic information when something goes wrong
collect_diagnostic_info() {
  print_step "Collecting diagnostic information"
  local diag_dir="/tmp/dive25-diagnostics-$(date +%s)"
  mkdir -p "$diag_dir"
  
  show_progress "Saving diagnostic information to $diag_dir..."
  
  # Save compose logs
  if [ -f "$COMPOSE_LOG_FILE" ]; then
    cp "$COMPOSE_LOG_FILE" "$diag_dir/compose.log"
  fi
  
  # Save docker ps output
  docker ps -a > "$diag_dir/docker-ps.txt"
  
  # Save docker-compose config
  docker-compose config > "$diag_dir/docker-compose-config.txt" 2>/dev/null || true
  
  # Save docker network info
  docker network ls > "$diag_dir/docker-networks.txt"
  
  # Save docker volume info
  docker volume ls > "$diag_dir/docker-volumes.txt"
  
  # Get individual container logs
  mkdir -p "$diag_dir/container-logs"
  for container in $(docker-compose ps --services 2>/dev/null); do
    docker-compose logs --no-color "$container" > "$diag_dir/container-logs/$container.log" 2>/dev/null || true
  done
  
  # Save system information
  echo "Date: $(date)" > "$diag_dir/system-info.txt"
  echo "Hostname: $(hostname)" >> "$diag_dir/system-info.txt"
  echo "Docker version: $(docker --version)" >> "$diag_dir/system-info.txt"
  echo "Docker Compose version: $(docker-compose --version)" >> "$diag_dir/system-info.txt"
  
  success "Diagnostic information saved to $diag_dir"
  echo -e "${BOLD}To analyze this issue, please examine the diagnostic files at:${RESET}"
  echo -e "  ${CYAN}$diag_dir${RESET}"
}

# Function to clean up Docker remnants if startup fails
cleanup_docker_remnants() {
  print_step "Cleaning up Docker environment"
  
  # List any detached/unused containers
  local detached_containers=$(docker ps -a --filter "status=created" --filter "status=exited" --format "{{.Names}}" | grep -E 'dive25|keycloak|kong')
  if [ -n "$detached_containers" ]; then
    warning "Found detached containers that might interfere with startup:"
    echo "$detached_containers"
    
    show_progress "Removing detached containers..."
    for container in $detached_containers; do
      docker rm -f "$container" > /dev/null 2>&1 && echo "Removed container: $container" || echo "Failed to remove: $container"
    done
    success "Removed detached containers"
  fi
  
  # Clean up networks if needed
  show_progress "Checking for orphaned Docker networks..."
  local orphaned_networks=$(docker network ls --format "{{.Name}}" | grep -E 'dive25|keycloak|kong')
  if [ -n "$orphaned_networks" ]; then
    warning "Found potentially problematic networks:"
    echo "$orphaned_networks"
    
    show_progress "Pruning networks..."
    docker network prune -f > /dev/null 2>&1
    success "Pruned Docker networks"
  fi
  
  # Try restarting with minimal configuration
  show_progress "Attempting restart with minimal Docker configuration..."
  docker-compose up -d postgres mongodb > /dev/null 2>&1
  sleep 5
  docker-compose up -d keycloak kong > /dev/null 2>&1
  
  success "Docker environment cleanup complete"
}

# Function to check and build necessary Docker images
check_and_build_images() {
  print_step "Checking and Building Docker Images"
  
  # Check for the frontend image
  if ! docker images | grep -q "dive-mvp-frontend"; then
    show_progress "Building frontend Docker image..."
    
    if [ -f "frontend/Dockerfile" ]; then
      # Build the frontend image
      docker build -t dive-mvp-frontend:latest -f frontend/Dockerfile frontend/ || true
      
      if [ $? -eq 0 ]; then
        success "Frontend Docker image built successfully"
      else
        warning "Failed to build frontend Docker image. Will attempt to continue with deployment."
      fi
    else
      warning "Frontend Dockerfile not found at frontend/Dockerfile. Check your project structure."
    fi
  else
    info "Frontend Docker image already exists"
  fi
  
  # Check for the API image
  if ! docker images | grep -q "dive-mvp-api"; then
    show_progress "Building API Docker image..."
    
    if [ -f "api/Dockerfile" ]; then
      # Build the API image
      docker build -t dive-mvp-api:latest -f api/Dockerfile api/ || true
      
      if [ $? -eq 0 ]; then
        success "API Docker image built successfully"
      else
        warning "Failed to build API Docker image. Will attempt to continue with deployment."
      fi
    else
      warning "API Dockerfile not found at api/Dockerfile. Check your project structure."
    fi
  else
    info "API Docker image already exists"
  fi
}

